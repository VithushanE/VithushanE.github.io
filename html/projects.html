<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>My Projects</title>
    <link rel="stylesheet" href="../style.css">
    <script src="../script.js" defer></script>
    <style>
        body {
        font-family: 'Arial', sans-serif;
        background-color: #f7f9fc;
        color: #333;
    }
    nav {
        background-color: #343a40; /* Slate dark color */
    }
    .navbar-brand, .nav-link {
        color: #ffffff !important; /* White text for links */
    }
    .nav-link:hover {
        color: #ffc107 !important; /* Yellow hover effect */
    }
    footer {
        background-color: #343a40;
        color: #ffffff;
        text-align: center;
        padding: 1rem 0;
    }
    
    </style>



</head>


<body>
   
        
        <nav class="navbar navbar-expand" style="text-align: center;">

            <div class="container-fluid">
                <a class="navbar-brand" href="https://vithushane.github.io/">Home</a>
                <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation">
                    <span class="navbar-toggler-icon"></span>
                </button>
                <div class="collapse navbar-collapse" id="navbarNavAltMarkup">
                    <div class="navbar-nav">
                        <a class="nav-link" href="./projects.html">Projects</a>
                        <a class="nav-link" href="./articles.html">Articles</a>
                    </div>
                </div>
            </div>
        </nav>

 
    <main>

        <h1 style="text-align: center;">My Projects</h1>

    <!-- PROJECT 1 -->
        <div class="project-container">
            <div class="project-tile" onclick="toggleDescription(this)">
                <div class="project-icon">
                    <img src="../assets/Earthquake_image.jpeg" alt="Earthquake Damage Predictor">
                </div>
                <h2>Earthquake Damage Predictor</h2>
                <p class="short-description">Created a model which predicts earthquake damage to buildings</p>
                <div class="description" style="display: none;">
                    <p>In this competition, the objective was to predict the level of damage to buildings caused by the 2015 Gorkha earthquake in Nepal. The provided test dataset had an unlabeled target variable, so I aimed to build a model using the training dataset to accurately predict this target.
                        </p>
                        <p>
                        The process involved several key steps:
                    </p>
                    <p>
                        Data Integration: Combining multiple datasets to create a comprehensive training set.
                
                    
                    </p>
                     <p>Data Cleaning: Rigorous data cleaning ensured high-quality data, addressing any inconsistencies or missing values.</p>
                     <p> Feature Selection: Identifying and selecting relevant features that would contribute to effective modeling.</p>
                     <p>  Model Training and Evaluation: Given that the target variable represented a multiclass classification problem, I initially experimented with Decision Trees.</p>
                      <p>  I subsequently applied various ensemble methods, including Random Forest, LightGBM, XGBoost, and CatBoost. </p>
                      <p>  Ultimately, the Random Forest model emerged as the best performer, demonstrating strong predictive accuracy in assessing building damage levels.  </p> 
                        
                        For more details, you can refer to the original competition page <a href="https://www.drivendata.org/competitions/57/nepal-earthquake/page/134/">here</a></p>
                    <a href="https://github.com/VithushanE/Modeling-Earthquake-Damage?tab=readme-ov-file" target="_blank">View on GitHub</a>
                </div>
            </div>


    <!-- NLP 2 -->
            <div class="project-tile" onclick="toggleDescription(this)">
                <div class="project-icon">
                    <img src="../assets/NLP_Sentiment.png" alt="NLP Sentiment Analysis">
                </div>
                <h2></h2>
                <p class="short-description">Using NLP for Sentiment Analysis</p>
                <div class="description" style="display: none;">
                    <p>
                        For this project, I developed a sentiment analysis model using various supervised machine learning algorithms to classify customer reviews.
                    </p>
                    <p>
                        The dataset consists of movie theater reviews, with each entry containing two columns: the first column includes the text of the review (unstructured data), while the second column contains a binary rating (1 or 0), likely indicating whether the review is positive or negative. Below is an outline of the approach I followed to build and evaluate the model.
                    </p>
                    
                    <p>
                        Step 1: Data Exploration
                    </p>
                    <p>
                        After installing the necessary libraries and uploading the training and testing datasets, I began with an initial exploration of the data. This allowed me to understand the structure, quality, and distribution of the data. By examining the "Sentence" and "Polarity" columns, I gained insights into the text data (reviews) and their corresponding sentiment labels, which would guide further preprocessing and modeling decisions.
                    </p>
                    
                    <p>
                        Step 2: Modeling with Different Machine Learning Algorithms
                    </p>
                    <p>
                        Next, I developed a machine learning pipeline that incorporated a variety of algorithms to predict sentiment. To prepare the data, I first split the dataset into training and testing sets. I performed this split for both the "Sentence" (features) and "Polarity" (target variable) columns. The "Polarity" column, which contains the sentiment labels (positive or negative), was used as the target variable, while the "Sentence" column provided the textual data for feature extraction.
                    </p>
                    
                    <p>
                        The machine learning algorithms included in the pipeline were:
                    </p>
                    <p>
                        Logistic Regression (with L2 regularization), Decision Tree Classifier, XGBoost, CatBoost, Random Forest Classifier. These algorithms were chosen for their versatility in handling text data and their ability to deliver strong performance in classification tasks.
                    </p>
                    
                    <p>
                        Step 3: Assessing Machine Learning Models
                    </p>
                    <p>
                        After training each model using the defined pipeline, I evaluated their performance through a series of metrics, focusing primarily on the confusion matrix to examine the model's classification accuracy. This step allowed me to compare the performance of each model on both the training and testing datasets.
                    </p>
                    
                    <p>
                        The use of a train/test split was crucial to avoid data leakage, ensuring that the evaluation results were unbiased and reflective of the model's ability to generalize. Despite efforts to tune the models, I found that some models exhibited signs of data leakage, highlighting the importance of careful preprocessing and cross-validation to ensure robust model performance.
                    </p>
                    
                    <p>
                        Step 4: Logistic regression with different Hyperparameter Tuning Combinations
                    </p>
                    <p>
                        Ultimately, I found logistic regression to be the best performing model. I decided to go deeper by creating another ML pipeline, but this time specifically looking at lasso, ridge, and elasticnet within logistic regression. I also created separate grid search parameters for each regression and assessed each. Ultimately, Ridge regression was the best out of all the logistic regression variations.
                    </p>
                    
                    <p>
                        Step 5: Examining results from a business point of view
                    </p>
                    <p>
                        The high F1 and accuracy scores on the training data indicate that the model learned from the training dataset very well. However, the drop in performance on the test dataset suggests that the model may not perform as well on unseen data, potentially due to overfitting. Hyperparameter tuning was applied to the best model after comparing it with other models.
                    </p>
                    
                    <p>
                        From a business standpoint, it is reasonable to assume that some customer feedback could be misinterpreted by the model, possibly due to variations in customers' grammar or the use of sarcasm. Given these considerations, I am satisfied with an overall accuracy of 0.76 on the testing dataset for the ridge model.
                    </p>
                    
                    <p>
                        Step 6: Visualizing Correct predictions with Label 0 and 1
                    </p>
                    
                    <a href="https://www.youtube.com/watch?v=oPVH-q8prYg" >View on YouTube</a>
                </div>
            </div>
        </div>



    </main>

    <footer>
        <p>&copy; 2024 Vithushan Esan</p>
    </footer>
</body>
</html>
